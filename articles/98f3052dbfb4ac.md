---
title: "【さらっと触りたい方へ】Amazon Bedrock を簡単に触ってみよう"
emoji: "🛏️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [AWS]
published: true
---
## はじめに

最近リリースされた Amazon Bedrock をご存知ですか？
楽しみにしていたサービスがリリースされたのでさらっと触って見ました！

技術的に不十分な説明になるかもしれませんが、こんな感じで触ることができますよーって感じだけ紹介しますね！

## Amazon Bedrockとは

Amazon Bedrockとは、様々な企業の基盤モデルを1つのAPIで利用できるサービスとなります。
難しいですね。
https://aws.amazon.com/jp/bedrock/

基盤モデル(Foundation Model)とは、大量のデータを使って事前に訓練された大規模な機械学習モデルのことをいいます。
用途としては、検索、翻訳やコンテンツ作成だけでなく医療品の開発などといった様々な分野で活用できるすごいやつです。

そのすごいやつが簡単にフルマネージドで使えるよっていうサービスが「Amazon Bedrock」です。

Amazon Bedrockをを使用することにより、Bedrock内で提供されている企業が開発したすごいやつを簡単に試すことができるだけなく、会社のデータを取り込み、カスタマイズをすることもできちゃいます。わくわくしますね。

といっても自宅には取り込むデータなんてないので、今回はすぐに触れる機能だけ触っていくような感じですすめていきます。。。

## まずはAmazon Bedrockを開いてみよう

ということでまずはコンソール画面からBedrockを開いてみましょう。

AWSマネジメントコンソールを開き、「bedrock」と検索欄に入力すると下記のようにヒットするので開きましょう。
![console_top](/images/98f3052dbfb4ac/2023-09-30-23-04-58.png)

東京や大阪リージョンで開いた人は下記のように使用できないから別のリージョン指定してねーと言われます。
下記の通り、使用可能なリージョンは現在オレゴン、シンガポール、バージニア北部、オハイオの4つでしか使えないのでそこから選択してリージョンを変更してあげてください。

![region_check](/images/98f3052dbfb4ac/2023-09-30-18-27-54.png)

これでBedrockのサービス画面が開きましたね。
最初からモデルを使えるわけではなく、有効化する必要があるので次からモデルを有効にして有効化したモデル遊んでみましょう。

## モデルを有効化して遊んでみよう

ということでモデルを登録していきましょう。
まずはメニュー左下の「**Model access**」をクリックしてください。 
![select_model_access](/images/98f3052dbfb4ac/2023-10-01-00-20-31.png)

モデルの登録画面が開くので右側の「Edit」をクリック

![model_access_go_edit](/images/98f3052dbfb4ac/2023-10-01-00-21-30.png)

使用したいモデルが選択できる画面が出てきましたね。
全部気になるのでチェック入れてしまいましょう。笑

ちなみに料金に関してはToken単位の従量課金となっています。

⚫︎ 料金
https://aws.amazon.com/jp/bedrock/pricing/

:::message
私の画面では使えるようになっていますが、Claudeは事前にAWS側にリクエストを送って承認されないと使用ができません。
一番楽しみなところなんですけどね・・・。
使用したい方は審査完了までにかなり時間がかかりますが、申請してみてください！
:::

![model_access_edit](/images/98f3052dbfb4ac/2023-09-30-18-50-48.png)

Access status が **Access granted** となるとモデルが使用可能になります。
(おまけでマーケットプレイスから登録したよーとメールが来ます。)

![model_access_home_1](/images/98f3052dbfb4ac/2023-09-30-18-55-09.png)

これで登録したモデルが使用できるようになりましたので、遊んでいきましょう！

## Amazon Bedrockで遊んでみよう

それでは順番に遊んでいってみましょう！
好きなモデルをーって感じですが、せっかくなのでTextとChatは承認されないと使えないClaudeを使って紹介していきますね！

### Chat で遊んでみよう

ではまずはChatで遊んでみましょう！

メニューから「**Chat**」をクリックしてチャットサービスの画面を開きましょう。

![chat_service_view](/images/98f3052dbfb4ac/2023-09-30-19-18-33.png)

次に「**Select model service**」をクリックし、使用したいモデルサービスを選択しましょう。

![select_model_service](/images/98f3052dbfb4ac/2023-09-30-19-22-19.png)

次に「**Select model**」をクリックし、使用したいモデルを選択しましょう。
![select_model](/images/98f3052dbfb4ac/2023-10-01-00-14-43.png)

これでチャットが使用可能になりました。
入力欄に質問を入力して「**Run**」をクリックすると答えを返してくれます！

なんとなくClaude v2 と ChatGPTの違いについて聞いてみました。
ChatGPTライクで日本語も適切でとてもｲｲﾃﾞｽﾈｪ

![chat_results](/images/98f3052dbfb4ac/2023-09-30-19-11-52.png)

さらにさらにですが、各種パラメータも変更することができます！
入力欄付近にある「**Add instructions**」と「**Update inference configurations**」について説明しますね。

#### Add instructions について

ChatGPTでいうCustom Instructions(カスタム指示)と同じようなものですね！
事前にここで制約条件や言葉遣いなどの指示を設定しておくことができます。

これにより、質問時の応答の仕方を制御することができます。
(といってもたまに忘れられますが...。)

![add_instructions](/images/98f3052dbfb4ac/2023-09-30-19-36-54.png)

こんな感じで口調などなどが変更できます。
![chat_pika](/images/98f3052dbfb4ac/2023-09-30-23-34-47.png)

### update inference configurationsについて

ここでChatGPTと同様、各種パラメータが変更することができます。
パラメータの詳細に関してはChatGPT関連の記事で詳しく解説されている方がたくさんいますので、そちらを参考にしてください。

ちなみに細かい部分はいいから返答の文字が途中で切れちゃうんだけどー。って方は、「**Max completion length**」の数値を上げると出力文字数の最大値が上がるのでやってみてください。

![inference_configurations](/images/98f3052dbfb4ac/2023-09-30-23-37-05.png)

では次にTextで遊んでみましょう！

### Text で遊んでみよう

メニューから「**Text**」をクリックしてチャットサービスの画面を開き、Chatの時と同様にサービスとモデルを選択しましょう！

![text](/images/98f3052dbfb4ac/2023-09-30-23-50-30.png)

あとは入力して「**Run**」をクリックするとテキストが出力されます。
(富山市民ですが、富山の観光スポット知らないので聞いてみました)

![text_response](/images/98f3052dbfb4ac/2023-09-30-23-56-25.png)

ここもchatと同様に右側の「**Inference configuration**」でパラメータの調整ができます。

では最後にImageで遊んでみましょう！

### Imageで遊んでみよう

ではメニューから「**Image**」を開きましょう。
現時点では Stable Diffusion のみモデルがあるので、それが最初から選択されています。

![image](/images/98f3052dbfb4ac/2023-09-30-23-59-18.png)

「**Prompt**」に作成したい画像の特徴を入力したあとに、「**Run**」をクリックすると画像が出力されます！
![image_response](/images/98f3052dbfb4ac/35F77207-459D-486B-A4E3-D7E538F3CD6E_1_105_c.jpeg)

ここも「**Inference configuration**」でパラメータの調整ができます。
色々いじってみると画像が変わるのでやってみてください！

## さいごに

ついにAWS上でも使えるようになりましたー！
今後も非常に楽しみなサービスとなっています。

ワークショップも日本語で公開されていますので、気になった方は一度やって見てください。(私はこれからやります...)

https://catalog.us-east-1.prod.workshops.aws/workshops/a4bdb007-5600-4368-81c5-ff5b4154f518/ja-JP/20-intro/21-environmentsetup


より詳しく知ってみたいぞと思った方は下記公式サイトを見るとより楽しめると思います。

⚫︎ 公式ブログ
https://aws.amazon.com/jp/blogs/aws/amazon-bedrock-is-now-generally-available-build-and-scale-generative-ai-applications-with-foundation-models/

⚫︎ 公式ドキュメント
https://docs.aws.amazon.com/bedrock/


それでは！
